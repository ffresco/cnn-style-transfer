<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_5qfax56cf4oi-0>li:before{content:"\0025cf  "}.lst-kix_5qfax56cf4oi-1>li:before{content:"\0025cb  "}.lst-kix_5qfax56cf4oi-2>li:before{content:"\0025a0  "}ul.lst-kix_79796cyfezu9-8{list-style-type:none}ul.lst-kix_79796cyfezu9-6{list-style-type:none}ul.lst-kix_79796cyfezu9-7{list-style-type:none}ul.lst-kix_79796cyfezu9-4{list-style-type:none}ul.lst-kix_79796cyfezu9-5{list-style-type:none}ul.lst-kix_79796cyfezu9-2{list-style-type:none}ul.lst-kix_79796cyfezu9-3{list-style-type:none}ul.lst-kix_79796cyfezu9-0{list-style-type:none}ul.lst-kix_79796cyfezu9-1{list-style-type:none}.lst-kix_79796cyfezu9-1>li:before{content:"\0025cb  "}.lst-kix_79796cyfezu9-0>li:before{content:"\0025cf  "}.lst-kix_79796cyfezu9-2>li:before{content:"\0025a0  "}.lst-kix_79796cyfezu9-3>li:before{content:"\0025cf  "}.lst-kix_5qfax56cf4oi-6>li:before{content:"\0025cf  "}.lst-kix_uf5yvqc6w7o4-8>li:before{content:"\0025a0  "}.lst-kix_5qfax56cf4oi-4>li:before{content:"\0025cb  "}.lst-kix_5qfax56cf4oi-5>li:before{content:"\0025a0  "}.lst-kix_5qfax56cf4oi-3>li:before{content:"\0025cf  "}ul.lst-kix_5qfax56cf4oi-8{list-style-type:none}.lst-kix_79796cyfezu9-8>li:before{content:"\0025a0  "}.lst-kix_79796cyfezu9-7>li:before{content:"\0025cb  "}.lst-kix_79796cyfezu9-5>li:before{content:"\0025a0  "}.lst-kix_uf5yvqc6w7o4-7>li:before{content:"\0025cb  "}.lst-kix_79796cyfezu9-4>li:before{content:"\0025cb  "}.lst-kix_79796cyfezu9-6>li:before{content:"\0025cf  "}.lst-kix_uf5yvqc6w7o4-5>li:before{content:"\0025a0  "}.lst-kix_uf5yvqc6w7o4-6>li:before{content:"\0025cf  "}.lst-kix_5qfax56cf4oi-7>li:before{content:"\0025cb  "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_uf5yvqc6w7o4-3>li:before{content:"\0025cf  "}.lst-kix_uf5yvqc6w7o4-4>li:before{content:"\0025cb  "}.lst-kix_5qfax56cf4oi-8>li:before{content:"\0025a0  "}ul.lst-kix_uf5yvqc6w7o4-0{list-style-type:none}ul.lst-kix_uf5yvqc6w7o4-1{list-style-type:none}ul.lst-kix_5qfax56cf4oi-0{list-style-type:none}.lst-kix_uf5yvqc6w7o4-0>li:before{content:"\0025cf  "}ul.lst-kix_uf5yvqc6w7o4-2{list-style-type:none}ul.lst-kix_5qfax56cf4oi-1{list-style-type:none}ul.lst-kix_uf5yvqc6w7o4-3{list-style-type:none}ul.lst-kix_5qfax56cf4oi-2{list-style-type:none}ul.lst-kix_uf5yvqc6w7o4-4{list-style-type:none}ul.lst-kix_5qfax56cf4oi-3{list-style-type:none}ul.lst-kix_uf5yvqc6w7o4-5{list-style-type:none}ul.lst-kix_5qfax56cf4oi-4{list-style-type:none}.lst-kix_uf5yvqc6w7o4-1>li:before{content:"\0025cb  "}.lst-kix_uf5yvqc6w7o4-2>li:before{content:"\0025a0  "}ul.lst-kix_uf5yvqc6w7o4-6{list-style-type:none}ul.lst-kix_5qfax56cf4oi-5{list-style-type:none}ul.lst-kix_uf5yvqc6w7o4-7{list-style-type:none}ul.lst-kix_5qfax56cf4oi-6{list-style-type:none}ul.lst-kix_uf5yvqc6w7o4-8{list-style-type:none}ul.lst-kix_5qfax56cf4oi-7{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c6{background-color:#f5f6f7;color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Courier New";font-style:normal}.c12{background-color:#fffffe;margin-left:36pt;padding-top:6pt;padding-bottom:5pt;line-height:1.3571428571428572;orphans:2;widows:2;text-align:left}.c8{background-color:#fffffe;margin-left:72pt;padding-top:6pt;padding-bottom:5pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c3{background-color:#ffffff;margin-left:72pt;padding-top:6pt;padding-bottom:5pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c13{color:#212121;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Roboto";font-style:normal}.c0{background-color:#ffffff;padding-top:6pt;padding-bottom:5pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c53{background-color:#fffffe;padding-top:6pt;padding-bottom:5pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c1{color:#008000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.5pt;font-family:"Courier New";font-style:normal}.c23{background-color:#fffffe;padding-top:6pt;padding-bottom:5pt;line-height:1.3571428571428572;orphans:2;widows:2;text-align:left}.c35{-webkit-text-decoration-skip:none;color:#ff0000;font-weight:400;text-decoration:underline;text-decoration-skip-ink:none;font-size:12pt;font-family:"Roboto"}.c7{background-color:#ffffff;padding-top:6pt;padding-bottom:5pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c24{background-color:#fffffe;padding-top:0pt;padding-bottom:0pt;line-height:1.3571428571428572;orphans:2;widows:2;text-align:left}.c11{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c4{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Roboto";font-style:normal}.c10{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c36{padding-top:-1pt;padding-bottom:-1pt;line-height:1.2857142857142858;orphans:2;widows:2;text-align:left}.c45{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:right}.c17{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c26{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c55{background-color:#f5f6f7;color:#000000;font-weight:400;font-size:12pt;font-family:"Courier New"}.c42{-webkit-text-decoration-skip:none;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-style:normal}.c21{background-color:#ffffff;color:#212121;font-weight:400;font-size:10.5pt;font-family:"Courier New"}.c38{background-color:#f5f6f7;color:#212121;font-weight:400;font-size:12pt;font-family:"Courier New"}.c41{background-color:#f5f6f7;font-size:12pt;font-family:"Courier New";color:#ff0000;font-weight:400}.c5{font-size:10.5pt;font-family:"Courier New";color:#09885a;font-weight:400}.c30{color:#000000;font-weight:400;font-size:10.5pt;font-family:"Courier New"}.c20{font-size:10.5pt;font-family:"Courier New";color:#267f99;font-weight:400}.c29{font-size:12pt;font-family:"Roboto";color:#212121;font-weight:400}.c58{color:#000000;font-weight:400;font-size:20pt;font-family:"Arial"}.c2{font-size:10.5pt;font-family:"Courier New";color:#a31515;font-weight:400}.c27{color:#000000;font-weight:700;font-size:10.5pt;font-family:"Courier New"}.c18{color:#000000;font-weight:400;font-size:11pt;font-family:"Arial"}.c52{color:#0000ff;font-weight:400;font-size:12pt;font-family:"Roboto"}.c25{color:#212121;font-weight:400;font-size:19.5pt;font-family:"Roboto"}.c32{font-size:10.5pt;font-family:"Courier New";color:#795e26;font-weight:400}.c9{font-size:10.5pt;font-family:"Courier New";color:#ff0000;font-weight:400}.c33{color:#ff0000;font-weight:700;font-size:10.5pt;font-family:"Courier New"}.c16{color:#000000;font-weight:700;font-size:11pt;font-family:"Arial"}.c39{font-size:12pt;font-family:"Roboto";color:#ff0000;font-weight:700}.c28{font-size:12pt;font-family:"Roboto";color:#212121;font-weight:700}.c31{color:#4a86e8;font-weight:700;font-size:10.5pt;font-family:"Courier New"}.c19{font-size:10.5pt;font-family:"Courier New";color:#0000ff;font-weight:400}.c37{font-size:10.5pt;font-family:"Courier New";color:#001080;font-weight:400}.c43{font-size:10.5pt;font-family:"Courier New";color:#212121;font-weight:700}.c44{font-size:10.5pt;font-family:"Courier New";font-weight:400}.c40{text-decoration:none;vertical-align:baseline;font-style:italic}.c60{color:#008000;font-size:10.5pt;font-family:"Courier New"}.c15{text-decoration:none;vertical-align:baseline;font-style:normal}.c65{font-size:12pt;font-family:"Courier New";color:#212121}.c61{font-size:12pt;font-family:"Roboto"}.c51{max-width:451.4pt;padding:72pt 72pt 72pt 72pt}.c56{padding:0;margin:0}.c62{color:#ff0000;font-weight:400}.c63{color:#000000;font-weight:400}.c48{margin-left:36pt;padding-left:0pt}.c22{background-color:#ffffff}.c34{margin-left:72pt}.c54{height:20pt}.c59{color:#af00db}.c57{background-color:#f5f6f7}.c64{margin-left:36pt}.c46{font-weight:700}.c49{color:#098658}.c47{font-style:italic}.c14{height:11pt}.c50{text-indent:36pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c22 c51"><div><p class="c45"><span class="c18 c15">Trabajo Final CNN &nbsp;- Fernando Fresco</span></p></div><h1 class="c11 c54" id="h.hrdx6ms41mcu"><span class="c58 c15"></span></h1><h1 class="c11" id="h.b4za45affmq0"><span class="c58 c15">Trabajo Final CNN - Style Transfer</span></h1><p class="c10"><span class="c16 c15"></span></p><p class="c17"><span class="c46">A</span><span class="c16 c15">-Im&aacute;genes de contenido provistas</span></p><p class="c24"><span class="c1"># Imagen para estilo</span></p><p class="c24"><span class="c19">!</span><span class="c44">wget https://upload.wikimedia.org/wikipedia/commons/</span><span class="c44 c49">5</span><span class="c44">/</span><span class="c44 c49">52</span><span class="c15 c30">/La_noche_estrellada1.jpg</span></p><p class="c24 c14"><span class="c30 c15"></span></p><p class="c24"><span class="c1"># Imagen para contenido</span></p><p class="c24"><span class="c19">!</span><span class="c44">wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/</span><span class="c44 c49">775</span><span class="c30 c15">px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg</span></p><p class="c24 c14"><span class="c30 c15"></span></p><p class="c24"><span class="c1"># Creamos el directorio para los archivos de salida</span></p><p class="c24"><span class="c19">!</span><span class="c30 c15">mkdir /content/output</span></p><p class="c24 c14"><span class="c30 c15"></span></p><p class="c24"><span class="c27 c15">B-Im&aacute;genes a utilizar en el trabajo</span></p><p class="c7"><span class="c61 c62">IMAGEN CONTENIDO:</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 366.67px;"><img alt="" src="images/image10.jpg" style="width: 601.70px; height: 366.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7"><span class="c4">IMAGEN ESTILO</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 664.00px;"><img alt="" src="images/image8.jpg" style="width: 601.70px; height: 664.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c24 c14"><span class="c27 c15"></span></p><p class="c24 c14"><span class="c27 c15"></span></p><p class="c24 c14"><span class="c15 c27"></span></p><h1 class="c11" id="h.nlc4u8pwfett"><span class="c15 c58">Respuestas</span></h1><h1 class="c26 c22" id="h.dm9l8kz9jtsb"><span class="c25 c15">1) En base a lo visto en el paper &iquest;Qu&eacute; significan los par&aacute;metros definidos en la siguiente celda?</span></h1><p class="c10"><span class="c16 c15"></span></p><p class="c17"><span class="c16 c15">1-Seteo variables pesos</span></p><p class="c7"><span class="c28 c15">*-Total_variation_weight:</span></p><p class="c7"><span class="c13">Este peso est&aacute; destinado al t&eacute;rmino, &nbsp;total_variational_weight_looss (cu&aacute;nto va a pesar en la funci&oacute;n de costo total). </span></p><p class="c7"><span class="c13">La total variational loss, es una funci&oacute;n de costo que eval&uacute;a la variaci&oacute;n entre vecinos cercanos (en t&eacute;rminos pr&aacute;cticos la que esa es tomar una fila y restarla a &nbsp;la fila superior, y lo mismo entre columnas restando la del lateral). Consiguiendo que la imagen final tenga bordes m&aacute;s suaves.</span></p><p class="c7"><span class="c13">M&aacute;s abajo se explica cual es el objetivo de esta loss (ver punto 5)</span></p><p class="c7"><span class="c13">Esta variaci&oacute;n se calcula sobre el contenido (no sobre las matrices de gram). En nuestra funci&oacute;n de costo total (en la versi&oacute;n original de la notebook entregada), &nbsp;le estamos indicando que va a tener un peso del 0.1. </span></p><p class="c7"><span class="c13">Si este peso es muy alto, la imagen de contenido reduce la diferencia entre p&iacute;xeles vecinos a tal punto que se pueden perder las divisiones y mezclar los colores (En la secci&oacute;n 5, genere una imagen con este peso en 100 para ver el resultado).</span></p><p class="c7 c14"><span class="c13"></span></p><p class="c7"><span class="c28">*-Style_weight:</span><span class="c13">&nbsp;</span></p><p class="c7"><span class="c13">Es el peso que le voy a dar en la funci&oacute;n de costo total, al t&eacute;rmino de la loss que trata de minimizar el error en estilo, contra la imagen de ruido blanco. </span></p><p class="c7"><span class="c13">Lo que se minimiza es el MSE entre las matrices de gram de los features a la salida de las capas de estilo (en este caso son 5 capas) de la imagen de estilo y la imagen aleatoria creada para ir ajustando. &nbsp;(se adjunta en el punto 5 las curvas de loss con diferentes pesos, y las im&aacute;genes de resultado con diferentes pesos)</span></p><p class="c7"><span class="c28">*-Content_weight:</span><span class="c13">&nbsp;es el peso que le voy a dar en la funci&oacute;n de costo total, al t&eacute;rmino de la loss que trata de minimizar el error en el contenido, contra la imagen de ruido blanco</span></p><p class="c7 c14"><span class="c13"></span></p><p class="c7"><span class="c28 c15">2-Seteo de escala im&aacute;genes</span></p><p class="c7"><span class="c13">Luego establece el tama&ntilde;o de las im&aacute;genes que se usar&aacute;n en la funci&oacute;n img_to_array. </span></p><p class="c7"><span class="c13">Para esto asigna 400 al alto o filas (esto se asigna directamente)</span></p><p class="c7"><span class="c13">En la l&iacute;nea siguiente se calculan las columnas que tendr&aacute; la imagen (o el ancho). Dicho ancho se saca calculando el ratio de la altura asignada 400 sobre la altura original (400/altura original) * ancho_original. As&iacute; consigue el nuevo ancho, que mantiene proporci&oacute;n con el alto asignado.</span></p><p class="c0"><span class="c4">Ejemplo del cambio de dimensiones para ver la transformaci&oacute;n</span></p><p class="c8"><span class="c32">print</span><span class="c9 c15">(height,width)</span></p><p class="c3"><span class="c21">599 775 -&gt;Original</span></p><p class="c8"><span class="c9 c15">print (img_nrows,img_ncols)</span></p><p class="c3"><span class="c21">400 517 -&gt;Transformada</span></p><p class="c23 c14"><span class="c9 c15"></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7 c14"><span class="c21 c15"></span></p><p class="c7 c14"><span class="c21 c15"></span></p><p class="c7 c14"><span class="c21 c15"></span></p><h1 class="c26 c22" id="h.y41h7yzc15cw"><span class="c25 c15">2) Explicar qu&eacute; hace la siguiente celda. En especial las &uacute;ltimas dos l&iacute;neas de la funci&oacute;n antes del return. &iquest;Por qu&eacute;?</span></h1><p class="c7"><span class="c28">1-np.expand_dims</span><span class="c13">: Le agrega otra dimensi&oacute;n a la numpy array en la posici&oacute;n indicada. Esto se hace porque la entrada de la red, est&aacute; dada por (batch Size, alto, ancho, canales). </span></p><p class="c7"><span class="c29">En este caso cuando cargo la imagen solo tengo (alto, ancho y los canales). Para poder conseguir el formato de entrada que admite la funci&oacute;n preproces_input. Aplic&oacute; </span><span class="c28">expand_dim </span><span class="c13">y paso de esto (400, 517, 3) a esto (1, 400, 517, 3)</span></p><p class="c7 c14"><span class="c21 c15"></span></p><p class="c7 c14"><span class="c13"></span></p><p class="c0"><span class="c4">Ejemplo del cambio de shape</span></p><p class="c8"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;antes&quot;</span><span class="c9 c15">,img.shape)</span></p><p class="c3"><span class="c21">antes (400, 517, 3)</span></p><p class="c8"><span class="c9">img = np.expand_dims(img, axis=</span><span class="c5">0</span><span class="c9 c15">)</span></p><p class="c8"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;despues&quot;</span><span class="c9 c15">,img.shape)</span></p><p class="c3"><span class="c21">despu&eacute;s (1, 400, 517, 3)</span></p><p class="c14 c53"><span class="c9 c15"></span></p><p class="c7 c14"><span class="c4"></span></p><hr><p class="c10"><span class="c18 c15"></span></p><p class="c7"><span class="c28">2-preprocess_input</span><span class="c13">: La funci&oacute;n preprocess_input est&aacute; destinada a adecuar una imagen al formato que requiere el modelo. </span></p><p class="c7"><span class="c29">Algunos modelos utilizan im&aacute;genes con valores que van de 0 a 1 (ser&iacute;a la versi&oacute;n normalizada). Otros, de -1 a +1. El que usamos en este momento que es el </span><span class="c28">vgg19 &nbsp;</span><span class="c29">&quot;caffe&quot; (papper p&aacute;gina 9 </span><span class="c28">&ldquo;The model is publicly available and can be explored in the caffe-framework.24&rdquo;</span><span class="c13">), no est&aacute; normalizado, sino centrado a cero. </span></p><p class="c7"><span class="c13">Entonces &nbsp;esta funci&oacute;n preproce_image hace lo siguiente:</span></p><ul class="c56 lst-kix_5qfax56cf4oi-0 start"><li class="c7 c48 li-bullet-0"><span class="c13">Recibe el path de la imagen </span></li><li class="c7 c48 li-bullet-0"><span class="c13">Carga la imagen en memoria </span></li><li class="c7 c48 li-bullet-0"><span class="c13">Convierte la imagen &nbsp;en un array. </span></li><li class="c7 c48 li-bullet-0"><span class="c13">Le agrega la dimensi&oacute;n del batch (como se explic&oacute; antes) </span></li><li class="c7 c48 li-bullet-0"><span class="c29">Aca se invoca a </span><span class="c28">preprocess_input, </span><span class="c13">y le pasamos el array obtenido antes, y nos retorna el formato adecuado para entrar en la red. </span></li></ul><p class="c10"><span class="c18 c15"></span></p><p class="c7 c14"><span class="c4"></span></p><h1 class="c22 c26" id="h.sg986xftjl84"><span class="c25 c15">3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qu&eacute; hace la siguiente celda. &iquest;Qu&eacute; relaci&oacute;n tiene con la celda anterior?</span></h1><p class="c10"><span class="c16 c15"></span></p><p class="c7"><span class="c28 c15">Objetivo funci&oacute;n deprocess_image:</span></p><p class="c7"><span class="c13">La VGG trabaja retornando im&aacute;genes BGR y centradas a cero.</span></p><p class="c7"><span class="c13">Para poder ver la imagen o guardarla como jpg necesito pasarla a RGB con valores de p&iacute;xel de [0,255]. </span></p><p class="c7"><span class="c13">El objetivo de esta funci&oacute;n es hacer esta conversi&oacute;n de lo que retorna la VGG (RGB centrado a cero) a BGR con valores [0,255]</span></p><p class="c7 c14"><span class="c13"></span></p><p class="c7"><span class="c28 c15">Como lo hace</span></p><p class="c7"><span class="c28">1-Quitamos el centrado a cero:</span><span class="c13">&nbsp;Para realizar esto sumamos esas medias (que son n&uacute;meros fijos 103.939;116.779;123.68)</span></p><p class="c7"><span class="c13">El origen de estos n&uacute;meros &nbsp;viene del entrenamiento de la red original. La red se entren&oacute; con im&aacute;genes, y cuando se calcul&oacute; la media por canal tomando todos las im&aacute;genes arroj&oacute; esos valores.</span></p><p class="c7"><span class="c13">Entonces de las im&aacute;genes que resultan a la salida, asumimos que sum&aacute;ndole la media la media por canal, &nbsp;volver&aacute;n al rango original (remover el centrado a cero). Para eliminar los casos donde despu&eacute;s de sumar la media no quede en el rango correcto [0.255], aplicamos un numpy.clip(0,255)--&gt; los valores por debajo de cero pasan a cero y los que superen 255 quedan en 255.</span></p><p class="c7"><span class="c13">Luego tengo que revertir el orden de los canales pasar de BGR &rarr; RGB, para reasigno la variable x, recorriendo el &uacute;ltimo eje (el de los canales) de atr&aacute;s para adelante.</span></p><p class="c7"><span class="c4">*Ejemplo de numpy clip:</span></p><p class="c23 c34"><span class="c1">###Ejemplo: Clip</span></p><p class="c23 c34"><span class="c9">ejemplo_ff= np.arange(</span><span class="c5">12</span><span class="c9 c15">) </span></p><p class="c23 c34"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;antes de clip &quot;</span><span class="c9 c15">,ejemplo_ff)</span></p><p class="c23 c34"><span class="c9">ejemplo_yy=np.clip(ejemplo_ff, </span><span class="c5">3</span><span class="c9">, </span><span class="c5">6</span><span class="c9 c15">) </span></p><p class="c23 c34"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;despues de clip&quot;</span><span class="c9 c15">,ejemplo_yy)</span></p><p class="c23 c34"><span class="c21 c15">antes de clip &nbsp;[ 0 &nbsp;1 &nbsp;2 &nbsp;3 &nbsp;4 &nbsp;5 &nbsp;6 &nbsp;7 &nbsp;8 &nbsp;9 10 11]</span></p><p class="c23 c34"><span class="c21">despues de clip [3 3 3 3 4 5 6 6 6 6 6 6]</span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7 c14"><span class="c15 c61 c63"></span></p><h1 class="c26 c22" id="h.foma1q8qyldh"><span class="c15 c25">4) En la siguientes celdas:</span></h1><ul class="c56 lst-kix_79796cyfezu9-0 start"><li class="c7 c48 li-bullet-0"><span class="c13">&iquest;Qu&eacute; es la matriz de Gram?&iquest;Para qu&eacute; se usa?</span></li><li class="c7 c48 li-bullet-0"><span class="c13">&iquest;Por qu&eacute; se permutan las dimensiones de x?</span></li></ul><p class="c7"><span class="c28">1-Matriz de gram:</span><span class="c13">&nbsp;Nos mide la correlaci&oacute;n entre vectores, en este caso la usamos para ver cu&aacute;n similares son los features maps a la salida de una capa entre s&iacute;. </span></p><p class="c7"><span class="c13">Si la multiplicaci&oacute;n de los vectores da un n&uacute;mero alto entonces est&aacute;n &nbsp;altamente correlacionado, una n&uacute;mero bajo poca correlaci&oacute;n. </span></p><p class="c7"><span class="c13">La idea es que sea cual sea la relaci&oacute;n entre features maps, la imagen random busque imitar esa correlaci&oacute;n.</span></p><p class="c7"><span class="c28 c15">2-Para que se usa: </span></p><p class="c7"><span class="c13">La matriz de Gram es una matriz de covarianza emp&iacute;rica. </span></p><p class="c7"><span class="c13">Para la transferencia de estilo, calcularemos las matrices gram de los features maps en un conjunto de capas inferiores de la red (las destinadas a estilo).</span></p><p class="c7"><span class="c13">Para explicar esto podemos tomar una sola capa, suponga que tiene 32 mapas de caracter&iacute;sticas. La matriz de gram es la covarianza entre cada uno de los mapas de caracter&iacute;sticas. </span></p><p class="c7"><span class="c13">Lo que se mide es si, en una posici&oacute;n de p&iacute;xel en particular, la caracter&iacute;stica #X tiende a coincidir con la caracter&iacute;stica #Y. </span></p><p class="c7"><span class="c13">Por ejemplo, si en una imagen, siempre que tenga la caracter&iacute;stica #15 iluminada en un punto en particular, la caracter&iacute;stica #8 tambi&eacute;n se ilumina. Vamos a buscar que en la imagen destino el patr&oacute;n de coincidencia de caracter&iacute;sticas coincida.</span></p><p class="c7 c14"><span class="c13"></span></p><p class="c7"><span class="c28">3-Porque se permuta:</span><span class="c13">&nbsp;El objetivo es recibir una imagen y retornar la gram matrix de (vectores features por vectores features). Para eso necesitamos hacer una matriz de feature, cuyos lados sean los vectores de features &nbsp;maps &nbsp;que tenga a la salida de la capa convolucional. Donde cada vector tendr&aacute; una longitud = el alto*el ancho, del feature map. </span></p><p class="c7"><span class="c13">Pero primero tenemos que transformar el feature mas que es un Tensor con este formato ((Height, Weight, &nbsp;Feature = features maps)) &rarr; a un tensor que tenga n&uacute;mero de feature map &nbsp;en la primer dimensi&oacute;n y &nbsp;vector de 1 con el feature map aplanado en la segunda dimensi&oacute;n, quedar&iacute;a con este shape: &nbsp;(Feature Map, Height * Weight)</span></p><p class="c7 c14"><span class="c13"></span></p><p class="c7"><span class="c28 c15">Proceso</span></p><p class="c7"><span class="c13">Primero hacemos una permutaci&oacute;n de las dimensiones, poniendo como primer eje, el de los features, y dejando luego el alto y el ancho detr&aacute;s.</span></p><p class="c7"><span class="c29">Nosotros recibimos en el input un tensor con este shape (H,W,F = features maps) y lo tenemos que convertir a --&gt; (F=Features maps, H*</span><span class="c29 c40">W) </span></p><p class="c7"><span class="c29 c47">Entonces al permutar, nos queda atras altura y ancho, y podemos hacer un flaten de estos dos, sin tocar el eje que corresponde a features. O sea el resultante es un vector, de shape (Features, alto*</span><span class="c13">ancho). </span></p><p class="c7"><span class="c13">Luego resta hacer la transpuesta para que los mismos vectores que en una matriz son fila en la otra sean columna y se pueda hacer la multiplicaci&oacute;n de todos contra todos.</span></p><p class="c7 c14"><span class="c15 c52"></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7"><span class="c28 c15">Ejemplo:</span></p><p class="c7"><span class="c13">Supongamos que tengo 10 mapas de caracteres, de 4x4, entonces para armar la matriz de gam me quedan 10 vectores de 16 de largo. La matriz de gram va a ser de 10 x 10, que son los vectores que tengo.</span></p><p class="c7 c14"><span class="c13"></span></p><p class="c7"><span class="c13">Poniendo un print en la funci&oacute;n vemos el resultado, ac&aacute; se puede ver los distintos shape desde que recibimos X hasta que generamos la gram matrix en la funci&oacute;n. </span></p><p class="c7 c14"><span class="c39 c15"></span></p><p class="c7"><span class="c39 c15">Resultados del c&aacute;lculo:</span></p><p class="c3"><span class="c21">x recibido &nbsp;gram: (400, 656, 64) &rarr; </span><span class="c9 c15 c22">As&iacute; recibo los feature maps</span></p><p class="c3"><span class="c21">X permutado gram: (64, 400, 656) &rarr; </span><span class="c9 c15 c22">Permuto y pongo delante los FM</span></p><p class="c3"><span class="c21">x flatten &nbsp; gram; Tensor(&quot;Reshape:0&quot;, shape=(64, 262400), dtype=float32) &rarr; </span><span class="c9 c15 c22">genero un vector 2D (Feature maps, altor*ancho)</span></p><p class="c3"><span class="c21">x flatten transpuesta gram (262400, 64) &rarr; </span><span class="c9 c15 c22">Hago transpuesta para poder luego multiplicar vector contra vector</span></p><p class="c3"><span class="c21">matriz gram resultado &nbsp;(64, 64) &rarr; </span><span class="c9 c15 c22">Matriz resultado</span></p><p class="c7 c14 c64"><span class="c13"></span></p><p class="c7"><span class="c39 c15">Ejemplo simple de c&aacute;lculo de gram</span></p><p class="c23"><span class="c1">#Ejemplo:</span></p><p class="c23"><span class="c1">#Matriz de gram</span></p><p class="c23"><span class="c1">#Caso A: tengo un vector en la primer fila y el otro ortogonal, o sea hay poca correlaci&oacute;n, en la segunda fila la correlacion es maxima</span></p><p class="c23 c34"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;caso 1 TV&quot;</span><span class="c9 c15">)</span></p><p class="c23 c34"><span class="c9">aa = np.ones((</span><span class="c5">2</span><span class="c9">,</span><span class="c5">2</span><span class="c9">), dtype=</span><span class="c20">float</span><span class="c9 c15">)</span></p><p class="c23 c34"><span class="c9">aa[</span><span class="c5">0</span><span class="c9">]=</span><span class="c5 c15">1</span></p><p class="c23 c34"><span class="c9">aa[</span><span class="c5">1</span><span class="c9">][</span><span class="c5">0</span><span class="c9">]=</span><span class="c5 c15">-1</span></p><p class="c23 c34"><span class="c9">aa[</span><span class="c5">1</span><span class="c9">][</span><span class="c5">1</span><span class="c9">]=</span><span class="c5 c15">1</span></p><p class="c23 c34"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;matriz aa&quot;</span><span class="c9 c15">,aa)</span></p><p class="c23 c34"><span class="c9 c15">bb=np.transpose(aa)</span></p><p class="c23 c34"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;trasponemos aa &quot;</span><span class="c9 c15">,bb)</span></p><p class="c23 c34"><span class="c9 c15">cc=np.dot(aa,bb)</span></p><p class="c23 c34"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;resultado producto punto&quot;</span><span class="c9 c15">,cc)</span></p><p class="c23"><span class="c1">#Como vemos los vectores ortogales dio cero el producto y para los paralelos duplico su modulo</span></p><p class="c7 c14"><span class="c4"></span></p><p class="c3"><span class="c21 c15">caso 1 TV</span></p><p class="c3"><span class="c21 c15">matriz aa </span></p><p class="c3"><span class="c21 c15">[[ 1. &nbsp;1.]</span></p><p class="c3"><span class="c21 c15">&nbsp;[-1. &nbsp;1.]]</span></p><p class="c3"><span class="c21 c15">trasponemos aa &nbsp;</span></p><p class="c3"><span class="c21 c15">[[ 1. -1.]</span></p><p class="c3"><span class="c21 c15">&nbsp;[ 1. &nbsp;1.]]</span></p><p class="c3"><span class="c21 c15">resultado producto punto [[2. 0.]</span></p><p class="c3"><span class="c21">&nbsp;[0. 2.]]</span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7 c14"><span class="c4"></span></p><h1 class="c26 c22" id="h.y8cdc87rfkaf"><span class="c25 c15">5) Losses:</span></h1><p class="c10"><span class="c18 c15"></span></p><p class="c10"><span class="c18 c15"></span></p><p class="c7"><span class="c13">Explicar qu&eacute; mide cada una de las losses en las siguientes tres celdas.</span></p><p class="c7"><span class="c13">Rta: </span></p><p class="c7"><span class="c13">*Style_loss: </span></p><p class="c0"><span class="c13">Es la funci&oacute;n de costo para ajustar el estilo. </span></p><p class="c0"><span class="c13">Lo hace calculando el error cuadr&aacute;tico medio entre las matrices de gram de los features maps a la salida de cada una de las capas seleccionadas para estilo, para la imagen con el estilo (desde la cual quiero tomar el estilo pero no el contenido) y la imagen aleatoria (o de ruido blanco como la referencia el paper). </span></p><p class="c0"><span class="c13">En este caso son 5 matrices para una imagen fuente del estilo (Fuente) y 5 para la imagen destino (Destino), entonces el c&aacute;lculo ser&aacute;: MSE entre ([Gram(Fuente1)-Gram(Destino1)]+....+[Gram(Fuente5)-Gram(Destino5)]). </span></p><p class="c0"><span class="c13">Las capas que se utilizan, son las capas menos profundas de la red. Aca se marcan cuales son:</span></p><p class="c0 c14"><span class="c21 c15"></span></p><p class="c0"><span class="c33 c15 c22">block1_conv1 (3, 3, 3, 64) --&gt;Style</span></p><p class="c0"><span class="c21 c15">block1_conv2 (3, 3, 64, 64)</span></p><p class="c0"><span class="c33 c15 c22">block2_conv1 (3, 3, 64, 128) --&gt;Style</span></p><p class="c0"><span class="c21 c15">block2_conv2 (3, 3, 128, 128)</span></p><p class="c0"><span class="c33 c22">block3_conv1 (3, 3, 128, 256</span><span class="c9 c22">) </span><span class="c33 c22">--&gt;Style</span></p><p class="c0"><span class="c21 c15">block3_conv2 (3, 3, 256, 256)</span></p><p class="c0"><span class="c21 c15">block3_conv3 (3, 3, 256, 256)</span></p><p class="c0"><span class="c21 c15">block3_conv4 (3, 3, 256, 256)</span></p><p class="c0"><span class="c33 c15 c22">block4_conv1 (3, 3, 256, 512) --&gt;Style</span></p><p class="c0"><span class="c21 c15">block4_conv2 (3, 3, 512, 512)</span></p><p class="c0"><span class="c21 c15">block4_conv3 (3, 3, 512, 512)</span></p><p class="c0"><span class="c21 c15">block4_conv4 (3, 3, 512, 512)</span></p><p class="c0"><span class="c15 c22 c33">block5_conv1 (3, 3, 512, 512)--&gt;Style</span></p><p class="c0"><span class="c44 c15 c22 c49">block5_conv2 (3, 3, 512, 512)--&gt;Contenido</span></p><p class="c0"><span class="c21 c15">block5_conv3 (3, 3, 512, 512)</span></p><p class="c0"><span class="c21 c15">block5_conv4 (3, 3, 512, 512)</span></p><p class="c0 c14"><span class="c21 c15"></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 600.00px; height: 344.00px;"><img alt="" src="images/image13.jpg" style="width: 600.00px; height: 344.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7 c14"><span class="c13"></span></p><p class="c0"><span class="c28 c15">*content_loss: </span></p><p class="c0"><span class="c13">Aca la funci&oacute;n de costo es m&aacute;s simple, es un error cuadr&aacute;tico medio de un &nbsp;feature map contra otro feature map (sin realizar c&aacute;lculos con el contenido del feature map). Entonces tom&oacute; el feature map a la salida de la capa seleccionada para contenido de: En primer lugar la imagen aleatoria (la cual es input de la red, y es este input el que se entrena, ac&aacute; entrenamos o ajustamos la imagen no los pesos de la red, &nbsp;para que su contenido en la pr&oacute;xima pasada reduzca el error), &nbsp;en segundo lugar la imagen fuente de la cual voy a copiar el contenido (pero no el estilo). Con estos dos features maps, resto uno al otro y calculo el error cuadr&aacute;tico medio. </span></p><p class="c0"><span class="c29">Las capas que se usan ac&aacute; son las m&aacute;s cercanas a la salida. En este ejemplo usamos la &ldquo;</span><span class="c44 c22 c49">block5_conv2</span><span class="c13">&rdquo;</span></p><p class="c0"><span class="c28 c15">*Total variational weight: </span></p><p class="c0"><span class="c13">Esto es un agregado que no est&aacute; en el paper. Lo que calcula es la variaci&oacute;n dentro de la misma imagen entre, en primer lugar las filas comparando la filas desde la posici&oacute;n 0 a la posici&oacute;n filas totales - 1, con las que van de la posici&oacute;n 1 hasta el final (filas totales) esto hace que compare cada fila con la que est&aacute; justo encima obteniendo la variaci&oacute;n entre las filas cercanas. </span></p><p class="c0"><span class="c13">Luego hace lo mismo con el ancho (que ser&iacute;an las columnas). </span></p><p class="c0"><span class="c13">Con lo cual termina obteniendo dos matrices con la diferencia entre vecinos cercanos. Luego las suma y les aplica una exponenciaci&oacute;n, y suma todos los resultados y as&iacute; se consigue un escalar que representa las diferencias absolutas para los valores de p&iacute;xeles vecinos en la imagen de entrada. </span></p><p class="c0"><span class="c13">Esto estar&iacute;a, de alguna forma, midiendo cu&aacute;nto ruido hay en las im&aacute;genes o cu&aacute;n fuerte son las transiciones. </span></p><p class="c0"><span class="c13">Si el n&uacute;mero obtenido es es grande hay mucha variaci&oacute;n, si es cero son vecinos id&eacute;nticos.</span></p><p class="c0"><span class="c13">Al agregar la variaci&oacute;n total a la funci&oacute;n de costo del entrenamiento la imagen resultante se ve mucho m&aacute;s suave. </span></p><p class="c0"><span class="c13">(Se realizaron &nbsp;pruebas variando el peso de esta loss y se adjuntan en el repo, con el sufijo tv_xx, donde xx es el peso asignado)</span></p><p class="c10"><span class="c18 c15"></span></p><p class="c7"><span class="c39">*</span><span class="c4">A continuaci&oacute;n un c&oacute;digo de prueba donde se verifica el c&aacute;lculo explicado con matrices peque&ntilde;as para su comprensi&oacute;n, mostrando el caso de un matriz donde los vecinos var&iacute;an mucho (loss grande) &nbsp;y otra donde no hay variaci&oacute;n (loss peque&ntilde;a):</span></p><p class="c12"><span class="c1">##Ejemplo:</span></p><p class="c12"><span class="c1">##Se realiza un ejemplo simple de lo que hace la Total Variational loss</span></p><p class="c12"><span class="c1">#Caso A: la diferencia entre vecinos es grande entre filas</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;caso 1 TV&quot;</span><span class="c9 c15">)</span></p><p class="c12"><span class="c9">aa = np.ones((</span><span class="c5">3</span><span class="c9">,</span><span class="c5">3</span><span class="c9">), dtype=</span><span class="c20">float</span><span class="c9 c15">)</span></p><p class="c12"><span class="c9">aa[</span><span class="c5">1</span><span class="c9">]=</span><span class="c5 c15">2</span></p><p class="c12"><span class="c9">aa[</span><span class="c5">2</span><span class="c9">]=</span><span class="c5 c15">5</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;Matriz A vecinos muy distintos&quot;</span><span class="c9 c15">,aa)</span></p><p class="c12"><span class="c9">tt=aa[:</span><span class="c5">2</span><span class="c9">, :] - aa[</span><span class="c5">1</span><span class="c9 c15">:, :]</span></p><p class="c12"><span class="c9">jj=aa[:,:</span><span class="c5">2</span><span class="c9">] - aa[:,</span><span class="c5">1</span><span class="c9 c15">:]</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;Diferencia filas&quot;</span><span class="c9">,tt,</span><span class="c2">&quot;Diferencia Columnas&quot;</span><span class="c9 c15">,jj)</span></p><p class="c12"><span class="c9 c15">ss=np.square(tt)</span></p><p class="c12"><span class="c9 c15">zz=np.square(jj)</span></p><p class="c12"><span class="c9">totalxx=K.</span><span class="c32">sum</span><span class="c9">(K.</span><span class="c32">pow</span><span class="c9">(ss, </span><span class="c5">1.25</span><span class="c9 c15">))</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;total variation A:&quot;</span><span class="c9">,K.</span><span class="c32">eval</span><span class="c9 c15">(totalxx))</span></p><p class="c12 c14"><span class="c9 c15"></span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;caso 2 TV&quot;</span><span class="c9 c15">)</span></p><p class="c12"><span class="c1">#Caso B: la diferencia entre vecinos es pequ&ntilde;a entre filas</span></p><p class="c12"><span class="c9">aa = np.ones((</span><span class="c5">3</span><span class="c9">,</span><span class="c5">3</span><span class="c9">), dtype=</span><span class="c20">float</span><span class="c9 c15">)</span></p><p class="c12"><span class="c9">aa[</span><span class="c5">1</span><span class="c9">]=</span><span class="c5 c15">1.1</span></p><p class="c12"><span class="c9">aa[</span><span class="c5">2</span><span class="c9">]=</span><span class="c5 c15">1.2</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;Matriz b vecinos parecidos&quot;</span><span class="c9 c15">,aa)</span></p><p class="c12"><span class="c9">tt=aa[:</span><span class="c5">2</span><span class="c9">, :] - aa[</span><span class="c5">1</span><span class="c9 c15">:, :]</span></p><p class="c12"><span class="c9">jj=aa[:,:</span><span class="c5">2</span><span class="c9">] - aa[:,</span><span class="c5">1</span><span class="c9 c15">:]</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;Diferencia filas&quot;</span><span class="c9">,tt,</span><span class="c2">&quot;Diferencia Columnas&quot;</span><span class="c9 c15">,jj)</span></p><p class="c12"><span class="c9 c15">ss=np.square(tt)</span></p><p class="c12"><span class="c9 c15">zz=np.square(jj)</span></p><p class="c12"><span class="c9">totalxx=K.</span><span class="c32">sum</span><span class="c9">(K.</span><span class="c32">pow</span><span class="c9">(ss, </span><span class="c5">1.25</span><span class="c9 c15">))</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;total variation B:&quot;</span><span class="c9">,K.</span><span class="c32">eval</span><span class="c9 c15">(totalxx))</span></p><p class="c12"><span class="c1">##Fin Ejemplo</span></p><p class="c12"><span class="c21 c15">caso 1 TV</span></p><p class="c12"><span class="c21 c15">Matriz A vecinos muy distintos [[1. 1. 1.]</span></p><p class="c12"><span class="c21 c15">&nbsp;[2. 2. 2.]</span></p><p class="c12"><span class="c21 c15">&nbsp;[5. 5. 5.]]</span></p><p class="c12"><span class="c21 c15">Diferencia filas [[-1. -1. -1.]</span></p><p class="c12"><span class="c21 c15">&nbsp;[-3. -3. -3.]] Diferencia Columnas [[0. 0.]</span></p><p class="c12"><span class="c21 c15">&nbsp;[0. 0.]</span></p><p class="c12"><span class="c21 c15">&nbsp;[0. 0.]]</span></p><p class="c12"><span class="c43 c15 c22">total variation A: 49.76537180435969</span></p><p class="c12"><span class="c21 c15">caso 2 TV</span></p><p class="c12"><span class="c21 c15">Matriz b vecinos parecidos [[1. &nbsp;1. &nbsp;1. ]</span></p><p class="c12"><span class="c21 c15">&nbsp;[1.1 1.1 1.1]</span></p><p class="c12"><span class="c21 c15">&nbsp;[1.2 1.2 1.2]]</span></p><p class="c12"><span class="c21 c15">Diferencia filas [[-0.1 -0.1 -0.1]</span></p><p class="c12"><span class="c21 c15">&nbsp;[-0.1 -0.1 -0.1]] Diferencia Columnas [[0. 0.]</span></p><p class="c12"><span class="c21 c15">&nbsp;[0. 0.]</span></p><p class="c12"><span class="c21 c15">&nbsp;[0. 0.]]</span></p><p class="c12"><span class="c22 c43">total variation B: 0.018973665961010265</span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7"><span class="c4">*A continuaci&oacute;n los gr&aacute;ficos de la loss con diferentes entrenamientos donde se asignaron distintos pesos, para entender como la magnitud de cada n&uacute;mero es diferentes, cuan r&aacute;pido converge cada una al m&iacute;nimo, y de esta forma asignar pesos en ratios que favorezcan la convergencia de la loss total. </span></p><p class="c7"><span class="c4">Seg&uacute;n lo mostrado en los gr&aacute;ficos, para mi la distribuci&oacute;n de pesos del caso C, es la mejor, porque iguala la magnitud de los escalares de cada loss, todos quedan cerca de 1xe10 aprox. En el caso D vemos como bajando la diferencia entre vecinos (Total variational loss con un alto pesos), se terminan por mezclar los bordes. &nbsp;</span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7"><span class="c4">IMAGEN CONTENIDO:</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 366.67px;"><img alt="" src="images/image10.jpg" style="width: 601.70px; height: 366.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c4">IMAGEN ESTILO</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 664.00px;"><img alt="" src="images/image8.jpg" style="width: 601.70px; height: 664.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c35">A-PESOS (Style=10, Content=1, Total Varitatinal=0) </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 440.00px;"><img alt="" src="images/image2.png" style="width: 601.70px; height: 440.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 366.67px;"><img alt="" src="images/image3.png" style="width: 601.70px; height: 366.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c39">Observaci&oacute;n: </span><span class="c4">Con la total variational en cero se puede ver en el contorno del cuerpo de la windsurfista que la transici&oacute;n es bien marcada con el agua. El estilo al estar con un peso de 10 gan&oacute; preponderancia y borr&oacute; algunos detalles de contenido como la cara de la persona.</span></p><p class="c7"><span class="c42 c39">B-PESOS (Style=10, Content=1, Total Varitatinal=0.1)</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 404.00px;"><img alt="" src="images/image12.png" style="width: 601.70px; height: 404.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 366.67px;"><img alt="" src="images/image9.png" style="width: 601.70px; height: 366.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c39">Observaci&oacute;n: </span><span class="c4">Con la total variational en 0.1, no difiere mucho del caso A</span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7"><span class="c42 c46 c49 c61">C-PESOS (Style=1, Content=10, Total Varitatinal=0.1)--&gt;Mejor</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 436.00px;"><img alt="" src="images/image1.png" style="width: 601.70px; height: 436.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 366.67px;"><img alt="" src="images/image4.png" style="width: 601.70px; height: 366.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c39">Observaci&oacute;n: </span><span class="c4">Con un peso de 10 para el contenido y 1 para el estilo, obtenemos la mejor versi&oacute;n, tenemos los colores del estilo, pero se puede distinguir mejor la cara, las rodillas y la punta de la tabla. </span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7"><span class="c42 c39">D-PESOS (Style=10, Content=1, Total Varitatinal=100)</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 418.67px;"><img alt="" src="images/image5.png" style="width: 601.70px; height: 418.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 366.67px;"><img alt="" src="images/image7.png" style="width: 601.70px; height: 366.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7"><span class="c39">Observaci&oacute;n: </span><span class="c4">Con la total variational en 100 al eliminar la variaci&oacute;n entre vecinos cercanos, vemos como por ejemplo en el borde que limita la espalda con el agua, se crea un borde fantasma donde se mezclan colores y se pierde nitidez. Y esto se puede comprobar en la loss del contenido que al tener poco peso, si bien la loss total mejora con las iteraciones, las loss de contenido por si sola empeora.</span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7"><span class="c42 c39">E-PESOS (Style=1, Content=10, Total Varitatinal=100)</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 429.33px;"><img alt="" src="images/image11.png" style="width: 601.70px; height: 429.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 366.67px;"><img alt="" src="images/image6.png" style="width: 601.70px; height: 366.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c39">Observaci&oacute;n: </span><span class="c4">Con la total variational en 100 se pierde nitidez como antes, pero ac&aacute;, con el peso invertido entre estilo y contenido, los bordes se mantienen un poco m&aacute;s n&iacute;tidos (por el peso mayor del contenido) y los colores se mezclan. </span></p><p class="c7 c14"><span class="c4"></span></p><h1 class="c26 c22" id="h.8lfcboqc2eh9"><span class="c25 c15">6) Explique el prop&oacute;sito de las siguientes tres celdas. &iquest;Qu&eacute; hace la funci&oacute;n fmin_l_bfgs_b? &iquest;En qu&eacute; se diferencia con la implementaci&oacute;n del paper? &iquest;Se puede utilizar alguna alternativa?</span></h1><p class="c7"><span class="c13">Respuesta:</span></p><p class="c7"><span class="c13">Antes de explicar las funciones requeridas, es necesario entender el objetivo que perseguimos con esta implementaci&oacute;n.</span></p><p class="c22 c36"><span class="c29">Lo que buscamos es actualizar</span><span class="c13">&nbsp;iterativamente nuestra imagen de salida de modo que minimice nuestra funci&oacute;n de costo. A diferencia de otras implementaciones, ac&aacute; no actualizamos los pesos asociados con nuestra red, sino que entrenamos nuestra imagen de entrada.</span></p><p class="c7 c14"><span class="c13"></span></p><p class="c7"><span class="c28 c15">1- La funcion fmin_l_bfgs_b:</span></p><p class="c7"><span class="c13">Lo que hace esta funci&oacute;n es, &nbsp;buscar un m&iacute;nimo para la funci&oacute;n que pasamos por par&aacute;metro usando el algoritmo L-BFGS-B. (B&uacute;squeda de m&iacute;nimos o de ra&iacute;ces, lo que hace por ejemplo regula falsi) </span></p><p class="c7"><span class="c29">Le estamos pasando: </span><span class="c29 c40">la funcion que quiero minimizar (funci&oacute;n de la cual quiero encontrar un &nbsp;input X que me de un m&iacute;nimo </span></p><p class="c7"><span class="c29 c40">Le pasamos entonces, el input actual (el X) donde estoy parado (esperamos que luego de aplicar la funci&oacute;n retorne un nuevo input, que minimice el resultado de la loss) </span></p><p class="c7"><span class="c4">*A continuaci&oacute;n un ejemplo de c&oacute;mo encuentra un m&iacute;nimo para funciones simples</span></p><p class="c23"><span class="c1">##EJEMPLO:</span></p><p class="c23"><span class="c1">##Como funciona la busqueda de minimos de fmin_l_bfgs</span></p><p class="c23"><span class="c1">#Aca tenemos un ejemplo corto de como minimiza la funcion F(x)=x^2, aca sabemos que el minimo es cero. Tiene que buscar el x que mas se aproxime a este valor</span></p><p class="c23"><span class="c1">#Le podria pasar args los args son constantes no los optimiza, pero me permiten por ejemplo:</span></p><p class="c23"><span class="c1">#si uso una recta tener diferentes pendientes en cada llamada, o si buscmo minimizar error cuadratico, le puedo pasar el par de Y_TRUE, para que vaya probando la resta</span></p><p class="c23"><span class="c1">#&#39;x&#39; y &#39;x0&#39; son los parametros que estoy optimizando - el resto es todo argumento</span></p><p class="c23 c14"><span class="c9 c15"></span></p><p class="c12"><span class="c1">#&lt;Caso A: X&sup2;&gt;:</span></p><p class="c12"><span class="c19">def</span><span class="c9">&nbsp;</span><span class="c32">func</span><span class="c9">(</span><span class="c37">x</span><span class="c9">, *</span><span class="c37">args</span><span class="c9 c15">):</span></p><p class="c12"><span class="c9">&nbsp; &nbsp;</span><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;x &quot;</span><span class="c9 c15">, x)</span></p><p class="c12"><span class="c9">&nbsp; &nbsp;</span><span class="c44 c59">return</span><span class="c9">&nbsp;(x**</span><span class="c5">2</span><span class="c9">) + </span><span class="c5 c15">1</span></p><p class="c12 c14"><span class="c9 c15"></span></p><p class="c12"><span class="c9">initial_values = np.array([</span><span class="c5">10</span><span class="c9 c15">])</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;initial_values &quot;</span><span class="c9 c15">, initial_values)</span></p><p class="c12 c14"><span class="c9 c15"></span></p><p class="c12"><span class="c9">tt, min_val, info &nbsp;=fmin_l_bfgs_b(func, x0=initial_values, args=(</span><span class="c5">0</span><span class="c9">,</span><span class="c5">0</span><span class="c9">), approx_grad=</span><span class="c19">True</span><span class="c9 c15">)</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;x:&quot;</span><span class="c9">,tt, </span><span class="c2">&quot;minval: &quot;</span><span class="c9">, min_val, </span><span class="c2">&quot;info :&quot;</span><span class="c9 c15">,info)</span></p><p class="c12"><span class="c9">y_true =(</span><span class="c5">-7.10542736e-15</span><span class="c9">)**</span><span class="c5">2</span><span class="c9">&nbsp;+ </span><span class="c5 c15">1</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;comprobacion del resultado&quot;</span><span class="c9 c15">,y_true)</span></p><p class="c12"><span class="c1">#&lt;/Caso A: X&sup2;&gt;</span></p><p class="c12"><span class="c21 c15">initial_values &nbsp;[10]</span></p><p class="c12"><span class="c21 c15">x &nbsp;[10.]</span></p><p class="c12"><span class="c21 c15">x &nbsp;[10.00000001]</span></p><p class="c12"><span class="c21 c15">x &nbsp;[9.]</span></p><p class="c12"><span class="c21 c15">x &nbsp;[9.00000001]</span></p><p class="c12"><span class="c15 c21">x &nbsp;[-7.10542736e-15]</span></p><p class="c12"><span class="c21 c15">x &nbsp;[9.99999289e-09]</span></p><p class="c12"><span class="c21">x: [-7.10542736e-15] minval: &nbsp;</span><span class="c31 c22">[1.]</span><span class="c21 c15">&nbsp;info : {&#39;grad&#39;: array([0.]), &#39;task&#39;: b&#39;CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL&#39;, &#39;funcalls&#39;: 6, &#39;nit&#39;: 2, &#39;warnflag&#39;: 0}</span></p><p class="c12"><span class="c21">comprobacion del resultado </span><span class="c31 c22">1.0</span></p><p class="c23 c14"><span class="c9 c15"></span></p><p class="c12"><span class="c1">#&lt;Caso B: MSE&gt;</span></p><p class="c12"><span class="c9">x_true = np.arange(</span><span class="c5">0</span><span class="c9">,</span><span class="c5">10</span><span class="c9">,</span><span class="c5">0.1</span><span class="c9 c15">)</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;valores x &quot;</span><span class="c9 c15">,x_true)</span></p><p class="c12"><span class="c9">m_true = </span><span class="c5 c15">2</span></p><p class="c12"><span class="c9">b_true = </span><span class="c5 c15">1.0</span></p><p class="c12"><span class="c9 c15">y_true = m_true*x_true + b_true</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;valor de y_true&quot;</span><span class="c9 c15">,y_true)</span></p><p class="c12 c14"><span class="c9 c15"></span></p><p class="c12"><span class="c19">def</span><span class="c9">&nbsp;</span><span class="c32">func</span><span class="c9">(</span><span class="c37">params</span><span class="c9">, *</span><span class="c37">args</span><span class="c9 c15">):</span></p><p class="c12"><span class="c9">&nbsp; &nbsp;</span><span class="c1">#print(&quot;params &quot;, params)</span></p><p class="c12"><span class="c9">&nbsp; &nbsp;</span><span class="c1">#print(&quot;args &quot;, args)</span></p><p class="c12"><span class="c9">&nbsp; &nbsp;x = args[</span><span class="c5">0</span><span class="c9 c15">]</span></p><p class="c12"><span class="c9">&nbsp; &nbsp;y = args[</span><span class="c5">1</span><span class="c9 c15">]</span></p><p class="c12"><span class="c9 c15">&nbsp; &nbsp;m, b = params</span></p><p class="c12"><span class="c9 c15">&nbsp; &nbsp;y_model = m*x+b</span></p><p class="c12"><span class="c9 c15">&nbsp; &nbsp;error = y-y_model</span></p><p class="c12"><span class="c9">&nbsp; &nbsp;</span><span class="c44 c59">return</span><span class="c9">&nbsp;</span><span class="c32">sum</span><span class="c9">(error**</span><span class="c5">2</span><span class="c9 c15">)</span></p><p class="c12 c14"><span class="c9 c15"></span></p><p class="c12"><span class="c9">initial_values = np.array([</span><span class="c5">0</span><span class="c9">, </span><span class="c5">0</span><span class="c9 c15">])</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;initial_values &quot;</span><span class="c9 c15">, initial_values)</span></p><p class="c12"><span class="c9">tt, min_val, info &nbsp;=fmin_l_bfgs_b(func, x0=initial_values, args=(x_true,y_true), approx_grad=</span><span class="c19">True</span><span class="c9 c15">)</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;x:&quot;</span><span class="c9">,tt, </span><span class="c2">&quot;minval: &quot;</span><span class="c9">, min_val, </span><span class="c2">&quot;info :&quot;</span><span class="c9 c15">,info)</span></p><p class="c12"><span class="c1">#Comprobacion del resultado</span></p><p class="c12"><span class="c9">y_calculado = tt[</span><span class="c5">0</span><span class="c9">]*x_true + tt[</span><span class="c5">1</span><span class="c9 c15">]</span></p><p class="c12"><span class="c9 c15">error = y_true-y_calculado</span></p><p class="c12"><span class="c32">print</span><span class="c9">(</span><span class="c2">&quot;comprobacion del resultado&quot;</span><span class="c9">,</span><span class="c32">sum</span><span class="c9">(error**</span><span class="c5">2</span><span class="c9 c15">))</span></p><p class="c12"><span class="c1">#&lt;/Caso B: MSE&gt;</span></p><p class="c12"><span class="c21 c15">valores x &nbsp;[0. &nbsp;0.1 0.2 0.3 0.4 &hellip;hasta&hellip;. &nbsp;20.2 20.4 20.6 20.8]</span></p><p class="c12"><span class="c21 c15">initial_values &nbsp;[0 0]</span></p><p class="c12"><span class="c21">x: [1.99999998 1.00000008] minval: &nbsp;</span><span class="c31 c22">2.3347348270214455e-13</span><span class="c21 c15">&nbsp;info : {&#39;grad&#39;: array([4.8017570e-07, 7.3179247e-08]), &#39;task&#39;: b&#39;CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL&#39;, &#39;funcalls&#39;: 24, &#39;nit&#39;: 5, &#39;warnflag&#39;: 0}</span></p><p class="c12"><span class="c21">comprobacion del resultado </span><span class="c31 c22">2.3347348270214455e-13</span></p><p class="c12 c14"><span class="c1"></span></p><p class="c23"><span class="c1">#Fin test de la funcion</span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7"><span class="c28">2</span><span class="c28 c15">-Diferencia:</span></p><p class="c7"><span class="c13">La diferencia con el paper es la variational loss, en el paper no se implementa esta funci&oacute;n, que como explique anteriormente sirve para suavizar las transiciones.</span></p><p class="c7 c14"><span class="c13"></span></p><p class="c7"><span class="c28 c15">3-Alternativa:</span></p><p class="c7"><span class="c29">Podemos usar diferentes alternativas para minimizar la funci&oacute;n de costo en vez de usar &ldquo;</span><span class="c28">fmin_l_bfgs_b</span><span class="c13">&rdquo;.</span></p><p class="c7"><span class="c29">Por ejemplo el &ldquo;</span><span class="c57 c46 c65">AdamOptimizer&rdquo;. </span><span class="c15 c38">Se adjunta una notebook donde se utiliz&oacute; este optimizador para buscar el m&iacute;nimo.</span></p><p class="c7"><span class="c38 c15">B&aacute;sicamente tendr&iacute;a que declarar como se ve a continuaci&oacute;n este optimizador, y aplicarlo a la imagen</span></p><p class="c7 c50"><span class="c6">opt = tf.train.AdamOptimizer(learning_rate=10.0)</span></p><p class="c7 c50"><span class="c41">grads, all_loss = </span><span class="c9 c15 c57">eval_loss_and_grads(x)</span></p><p class="c7 c50"><span class="c6">opt.apply_gradients([(grads, init_image)])</span></p><p class="c7"><span class="c15 c55">Y de esta manera obtener init_image minimizada</span></p><p class="c7 c14"><span class="c38 c15"></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7 c14"><span class="c4"></span></p><h1 class="c26 c22" id="h.wzeh6uefca44"><span class="c25 c15">7) Ejecute la siguiente celda y observe las im&aacute;genes de salida en cada iteraci&oacute;n.</span></h1><p class="c7 c14"><span class="c4"></span></p><p class="c7 c14"><span class="c4"></span></p><p class="c7 c14"><span class="c4"></span></p><h1 class="c26 c22" id="h.tw0o8vmds3xq"><span class="c25 c15">8) Generar im&aacute;genes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las im&aacute;genes generadas como archivos separados.)</span></h1><p class="c17"><span>Se explic&oacute; en el punto sobre la loss (Ver punto 5)</span></p><p class="c10"><span class="c18 c15"></span></p><p class="c10"><span class="c16 c15"></span></p><p class="c10"><span class="c16 c15"></span></p><p class="c10"><span class="c16 c15"></span></p><p class="c10"><span class="c16 c15"></span></p><p class="c10"><span class="c16 c15"></span></p><p class="c10"><span class="c15 c16"></span></p><p class="c10"><span class="c16 c15"></span></p><p class="c10"><span class="c18 c15"></span></p><p class="c10"><span class="c18 c15"></span></p><p class="c10"><span class="c18 c15"></span></p><p class="c10"><span class="c15 c18"></span></p></body></html>